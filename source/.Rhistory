library(readxl)
library(dplyr)
library(knitr)
library(ggplot2)
library(ggpubr)
library(pastecs)
library(kableExtra)
library (e1071)
library(lemon)
# Listado de modelos tuneados guardados
saved_models <- list.files("../models/tuned/")
# Modelado con kernel lineal
if("tuned_linmod02.Rds" %in% saved_models){
tuned_linmod02 <- readRDS("../models/tuned/tuned_linmod02.Rds")
print("Modelado con kernel lineal")
tuned_linmod02_sum <- summary(tuned_linmod02)
tuned_linmod02_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod02_sum$performances$error %>% sd()))
} else {
tuned_linmod02 <- tune(svm ,Class ~ ., data = train, kernel = "linear",
ranges =list(cost=seq(from = 1, to = 10, by=0.25) ),
tunecontrol = tune.control(cross=10))
saveRDS(tuned_linmod02,"../models/tuned/tuned_linmod02.Rds")
tuned_linmod01 <- readRDS("../models/tuned/tuned_linmod02.Rds")
print("Modelado con kernel lineal")
tuned_linmod02_sum <- summary(tuned_linmod02)
tuned_linmod02_sum %>% print()
print(paste0("Error promedio: ",tuned_linmod02_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_linmod02_sum$performances$error %>% sd()))
}
# Modelado refinado con kernel radial
if("tuned_radmod03.Rds" %in% saved_models){
tuned_radmod03 <- readRDS("../models/tuned/tuned_radmod03.Rds")
print("Modelado refinado con kernel radial")
tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
} else {
tuned_radmod03 <- tune(svm ,Class ~ ., data = st_train, kernel = "radial",
ranges =list(cost=2**seq(from=-5, to=10),
gamma=2**seq(from=-5, to=10)),
tunecontrol = tune.control(cross=5))
saveRDS(tuned_radmod03,"../models/tuned/tuned_radmod03.Rds")
tuned_radmod03 <- readRDS("../models/tuned/tuned_radmod03.Rds")
print("Modelado refinado con kernel radial")
tuned_radmod03_sum <- summary(tuned_radmod03)
print(tuned_radmod03_sum)
print(paste0("Error promedio: ",tuned_radmod03_sum$performances$error %>% mean(),
". Desv. típica del error: ", tuned_radmod03_sum$performances$error %>% sd()))
}
tuned_radmod03
svmfit <- tuned_radmod03$best.model
plot(svmfit , st_train)
saved_dbs <- list.files("../dbs/model_db/")
if("df_final.Rds" %in% saved_dbs){
df_final <- readRDS(file="../dbs/model_db/df_final.Rds")
} else {
df_final$Class <- as.factor(df_final$Class)
saveRDS(df_final, file="../dbs/model_db/df_final.Rds")
}
# Creamos los conjuntos de entrenamiento y test
df_final$id <- 1:nrow(df_final)
set.seed(210)
train <- df_final %>% dplyr::sample_frac(.75)
test  <- dplyr::anti_join(df_final, train, by = 'id')
# Eliminamos la columna id
train <- train[,!(names(train) %in% c("id"))]
test <- test[,!(names(test) %in% c("id"))]
# Estandarizamos el conjunto de entrenamiento.
st_train <- scale(train[,1:(ncol(train)-1)],center = TRUE, scale = TRUE) %>% as.data.frame()
st_train$Class <- train$Class # Espero estar incluyendo la clase en el mismo orden. Revisar.
# Calculamos el vector de medias y el vector de desviaciones estándar del conjunto train.
means <- train %>% summarise_if(is.numeric, mean)
st.devs <- train %>% summarise_if(is.numeric, sd)
# Restamos las medias y dividimos por las desviaciones estándar
st_test <- scale(test[,1:(ncol(test)-1)],center = means, scale = st.devs) %>% as.data.frame()
st_test$Class <- test$Class
plot(svmfit , st_train)
plot(svmfit$ , st_train, Class~.)
plot(svmfit , st_train, Class~.)
plot(svmfit , data=st_train)
plot(svmfit , st_train, Class~.)
st_train %>% sapply(class)
st_train %>%  mutate_if(is.factor, funs(as.numeric(as.character(.))))
st_train$Class
st_train$Class %>% as.numeric()
st_train$Class %>% as.character() %>% as.numeric()
st_train$Class <- st_train$Class %>% as.numeric()
plot(svmfit , st_train, Class~.)
plot(svmfit , st_train, Class~Area + Perimeter)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter+st_train$Major_Axis_Length+st_train$Minor_Axis_Length+st_train$Convex_Area)
tuned_radmod03$best.parameters
svmfit <-  svm(st_train$Class~., data=st_train, kernel ="radial",gamma =0.03125, cost=64)
plot(svmfit , st_train)
plot(svmfit , st_train)
plot(svmfit , st_train, st_train$Class~st_train$Area + st_train$Perimeter)
tuned_radmod03$best.parameters
tuned_radmod03$best.parameters$gamma
st_train$Class <- st_train$Class %>% as.numeric()
svmfit <-  svm(st_train$Class~., data=st_train,
kernel ="radial",
gamma =tuned_radmod03$best.parameters$gamma,
cost=tuned_radmod03$best.parameters$cost)
plot(svmfit , st_train)
plot(svmfit , st_train)
plot(svmfit , st_train)
p <- plot(svmfit , st_train)
print(p)
p <- plot(svmfit , st_train, formula = st_train$Class~.)
print(p)
?plot.svm
data(st_train)
st_train %>% data("bnr")
?data
p <- plot(svmfit , st_train, formula = Area~Perimeter)
p
p <- plot(svmfit , st_train, formula = st_train$Area~st_train$Perimeter)
p
library(readr)
car <- read.csv("~/Desktop/RTG/dataset/car.data.txt", header = F)
# V7: unacc, acc, good, vgood
roww <- nrow(car)
coll <- ncol(car)
numTrain <- floor((2/3) * roww)
numTest <- roww - numTrain
training <- car[sample(roww, numTrain), ]
library(readr)
cars
setwd("~/Documents/MUM/TFM/code/source")
library(dplyr)
db <- read.csv("../db/weatherAUS.csv")
db %>% View()
db %>% table()
db['Location'] %>% table() %>% View()
db %>% View()
na_count <-sapply(x, function(y) sum(length(which(is.na(db)))))
na_count <-sapply(db, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count %>% View
