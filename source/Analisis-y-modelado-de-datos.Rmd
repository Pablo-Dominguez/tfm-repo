---
title: "Análisis y modelado de datos"
author: "Pablo Domínguez"
date: '2022-06-23'
output:
  pdf_document:
    number_sections: no
    toc: yes
    toc_depth: 3    
bibliography: references.bib  
header-includes:
- \usepackage{booktabs}
- \usepackage{graphicx}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{caption}
- \usepackage{subcaption}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
- \usepackage[spanish,es-tabla]{babel}
---

```{r message=FALSE, echo=FALSE}
library(tidyverse)
library(kableExtra)
library(ggpubr)
library(randomForest)
library(mlbench)
library(caret)
library(FactoMineR)
library(factoextra)
library(mltools)
library(data.table)
library(cowplot)
```

\listoftables
\listoffigures

## Planteamiento del problema a abordar

Nos encontramos con un conjunto de datos obtenidos a partir de mediciones meteorológicas realizadas por el gobierno de Australia^[Notes about Daily Weather Observations - @NADWO]. Estos datos, recogidos en distintas localidades, se han capturado realizando mediciones diarias de temperatura, lluvia, evaporación, sol, viento, humedad etc. 

En la referencia mencionada advierten que el control de calidad aplicado a la captura de estos datos ha sido limitado, por lo que es posible que existan imprecisiones debidas a datos faltantes, valores acumulados tras varios datos faltantes o errores de varios tipos. Es por este motivo que empezaremos nuestro estudio realizando una revisión de la calidad y estructura del dato. Tras este proceso, construiremos una serie de variables que transformarán el problema y la estructura de datos para que puedan aplicarse los modelos de clasificación supervisada planteados.

Partiendo de la base de datos procesada, la segmentaremos para aplicar varios modelados diferentes por cada zona climática\footref{climate01}. Finalmente, compararemos los modelos, los ensamblaremos y presentaremos unos resultados de la precisión del modelo final.

Con esta aplicación práctica de los modelos teóricos abordados en el capítulo anterior buscamos reflejar la capacidad de herramientas matemáticas abstractas a la hora de resolver situaciones que pueden tener un gran beneficio en varios ámbitos, tales como sociales, económicos o medioambientales.

Para ello, nos basaremos en las pautas definidas en @CA a la hora de abordar un problema de clasificación supervisada, esto es:

1. Definir un conjunto de datos sobre los que modelar el problema de clasificación.
2. Seleccionar un conjunto de \textit{variables predictoras} relevante para el problema.
3. Tratar incorrecciones o valores faltantes.
4. Estandarizar variables.
5. Creación de nuevas variables.
6. Modelado del problema de clasificación con diferentes algoritmos.
7. Presentar, visualizar, comparar e interpretar los resultados.
8. Conclusiones.


## Origen de los datos y variable objetivo

El buró de metereología australiano coordina una serie de estaciones metereológicas locales repartidas a lo largo del territorio. De esta manera, recopila y reporta datos sobre mediciones meteorológicas. En nuestro caso, tenemos información de 49 ciudades repartida a lo largo de unos 8 años.



```{r Tab-1, echo=FALSE}

x <- "rep(\"---\", 6)"
xnew <- "---"

db <- read.csv("../db/weatherAUS.csv", stringsAsFactors = TRUE)
db$Date <- as.Date(db$Date, format="%Y-%m-%d")
columnas_enteras <- db[, unlist(lapply(db, is.integer), use.names = FALSE) ] %>% colnames()
db[,columnas_enteras] <- db[,columnas_enteras] %>% sapply(.,as.numeric)
attach(db)
db %>% head() %>%  select(-c(6:19)) %>% add_column(.,rep("---",6),.after = 5) %>% rename(., !!xnew := !!rlang::sym(x)) %>% kbl(., booktabs = T,caption = "Muestra de algunas filas y columnas del conjunto de datos") %>% kable_styling(latex_options = c("striped", "scale_down","hold_position")) 

# Voy a descomponer en:
# - trend
# - seasonality
# - noise
# 
# SMA(n):moving average of last n days --> smoothing
# decompose()
```


Destacar que hemos importado las variables tipo *string* como *factor*. En la tabla \ref{tab:Tab-2}, presentamos el tipo de cada variable.

```{r, echo=FALSE}
# Evaluamos los tipos de dato.
db_types <- sapply(db,class) %>% as.data.frame()
colnames(db_types) <- c("Data_types")
db_types01 <- db_types %>% slice(., 1:floor(nrow(db_types)/2))
db_types02 <- db_types %>% slice(., ceiling(nrow(db_types)/2):nrow(db_types))

kbl_types01 <- db_types01 %>% kbl(., booktabs = T, caption = "Tipos de las once primeras variables") %>% kable_styling(latex_options = c("striped","HOLD_position")
                                                                          ) 

kbl_types02 <- db_types02 %>% kbl(., booktabs = T, caption = "Tipos de las doce variables restantes") %>% kable_styling(latex_options = c("striped","HOLD_position")) 



#knitr::kables(list(db_types01 %>% kable(., booktabs = T,caption = "Left") %>% kable_styling(latex_options = c("striped","HOLD_position"), position="float_left"),
#                   db_types02 %>% kable(., booktabs = T,caption = "Right") %>% kable_styling(latex_options = c("striped","HOLD_position"),position="float_right"),caption = "Tipo de datos de las variables")) %>% kable_styling(latex_options = c("striped","HOLD_position")) 
```

```{r, echo=FALSE}
kbl_types01 <- gsub("\\begin{table}[H]", "\\begin{subtable}[b]{0.48\\linewidth}\n\n", kbl_types01, fixed = TRUE)
kbl_types01 <- gsub("\\end{table}", "\\end{subtable}", kbl_types01, fixed = TRUE) 

kbl_types02 <- gsub("\\begin{table}[H]", "\\begin{subtable}[b]{0.48\\linewidth}\n", kbl_types02, fixed = TRUE)
kbl_types02 <- gsub("\\end{table}", "\\end{subtable}", kbl_types02, fixed = TRUE) 
```

```{r Tab-2, results = "asis", echo=FALSE}
cat("",
    "\\begin{table}[!htb]",
    "\\centering",
    "\\caption{Tipo de datos de las variables}",
    kbl_types01,
    kbl_types02,
    "\\label{tab:Tab-2}",
    "\\end{table}",
    "",
    sep = "\n") 
```

De esta manera, según se refleja en @NADWO, el conjunto de datos con el que vamos a trabajar cuenta con las siguientes variables.

 - *Date*: Fecha en la que se realizó la medición, en formato *AAAA-MM-DD*.
 - *Location*: Localización donde se realizó la medición. 
 - *MinTemp*: Temperatura mínima alcanzada, medida en grados celsius \footnote{\label{hours01}En un rango de 24 horas desde las 9am.}. 
 - *MaxTemp*: Temperatura máxima alcanzada, medida en grados celsius\footref{hours01}.
 - *Rainfall*: Cantidad total de precipitación, medida en milímetros\footref{hours01}. 
 - *Evaporation*: Evaporación en milímetros sobre un *tanque evaporimétrico clase "A"*\footref{hours01}. 
 - *Sunshine*: Tiempo en horas de alto nivel de luminosidad solar\footnote{\label{hours02}En un rango de 24 horas desde las 12am.}.
 - *WindGustDir*: Dirección general del viento racheado a lo largo del día\footref{hours02}, tomando una de las 16 direcciones posibles del viento.
 - *WindGustSpeed*: Velocidad global del viento racheado a lo largo del día\footref{hours02}, medido en kilómetros por hora.
 - *WindDir9am*, *WindDir3pm*: Dirección promedio del viento en los 10 minutos previos a la hora indicada en cada variable.
 - *WindSpeed9am*, *WindSpeed3pm*: Velocidad promedio del viento en los 10 minutos previos a la hora indicada en cada variable, medida en kilómetros por hora.
 - *Humidity9am*, *Humidity3pm*: Humedad relativa, medida en tanto porciento, a las horas indicadas en cada variable.
 - *Pressure9am*, *Pressure3pm*: Presión atmosférica medida a nivel del mar a las horas indicadas en cada variable, usando el hectopascal como unidad de medida.
 - *Cloud9am*, *Cloud3pm*: Fracción del cielo cubierta por nubes a las horas indicadas, medida en *octas de cielo*.
 - *Temp9am*, *Temp3pm*: Temperatura en grados celsius medida a las horas indicadas.
 - *RainToday*, *RainTomorrow*: Variables binarias indicando si ha habido o no lluvia ese día. 

 
De este modo, *RainTomorrow* será nuestra variable objetivo en los clasificadores. Con ello, desarrollaremos estrategias buscando que los modelos puedan decidir lo mejor posible si, dadas las observaciones de un día e información agregada de días anteriores, lloverá o no al día siguiente.

## Información de los datos y filtrado de datos

A continuación, buscamos comprobar si la serie temporal está completa y sin días repetidos para cada valor de la variable *Location*. En la tabla \ref{tab:Tab-3}, se muestran las variables conteniendo la siguiente información.

 - *min_fec*, *max_fec*: Fecha donde comienzan y terminan los datos en la serie temporal.
 - *obs*: Número de observaciones total en cada serie temporal.
 - *rep*: Booleano que representa si existen fechas repetidas dentro de la serie temporal, esto es, *FALSE* indica ausencia de fechas repetidas.
 - *n_diff_dates*: Cantidad de fechas faltantes dentro de la serie temporal.
 - *top_diff_date*: Última fecha faltante en la serie temporal.
 - *range_free*: Cantidad de datos sin fechas faltates medidos hacia atrás desde el último registro. Es decir, longitud de la serie temporal continua más reciente.
 - *range*: Rango, medido en dias, de la serie temporal. Esto es, número de días entre *max_fec* y *min_fec*.

```{r  Tab-3, echo=FALSE}

# Creamos función que comprueba rango de fechas

err_cities <- c()
date_range <- function(){
  # Inicializamos los vectores
  min_fec <- c()
  max_fec <- c()
  obs <- c()
  rep <- c()
  n_diff_dates_vec <- c()
  top_diff_date_vec <- c()
  range_free_vec <- c()
  
  # Iteramos por cada ciudad
  for(city in levels(db$Location)){
    
    # Filtramos el ds por ciudad
    db_filtered <- db %>% filter(.,Location==city)
    
    # Calculamos y almacenamos el mínimo y el máximo de la variable Date
    mind <- format(as.Date(min(db_filtered$Date),format="%Y-%m-%d"))
    min_fec <- c(min_fec,mind)
    maxd <- format(as.Date(max(db_filtered$Date),format="%Y-%m-%d"))
    max_fec <- c(max_fec,maxd)
    
    # Comprobamos rangos de fecha
    fech_range <- seq(mind %>% as.Date(), maxd %>% as.Date(), "days")
    diff_dates <- setdiff(fech_range,db_filtered$Date) %>% as.Date(., origin="1970-01-01")
    if(length(diff_dates)>0){ # hay fechas faltantes
      top_diff_date <- max(diff_dates) %>% as.Date(., origin="1970-01-01")
      top_diff_date_vec <- c(top_diff_date_vec,top_diff_date)
      n_diff_dates <- length(diff_dates)
      n_diff_dates_vec <- c(n_diff_dates_vec,n_diff_dates)
      range_free <- seq(top_diff_date %>% as.Date(),maxd %>% as.Date(), "days") %>% length()
      range_free_vec <- c(range_free_vec,range_free)
    } else {
      top_diff_date_vec <- c(top_diff_date_vec,NA)
      n_diff_dates_vec <- c(n_diff_dates_vec,0)
      range_free_vec <- c(range_free_vec,NA)
    }
    obs <- c(obs,length(db_filtered$Date))
    rep <- c(rep,length(unique(db_filtered$Date))!=length(db_filtered$Date))
  }
  
  dates_df <- data.frame(min_fec,max_fec,obs,rep,n_diff_dates_vec,top_diff_date_vec,range_free_vec, stringsAsFactors=TRUE)
  dates_df$min_fec <- as.Date(dates_df$min_fec, format="%Y-%m-%d")
  dates_df$max_fec <- as.Date(dates_df$max_fec, format="%Y-%m-%d")
  dates_df <- mutate(dates_df, range = max_fec - min_fec+1)
  dates_df$top_diff_date_vec <- dates_df$top_diff_date_vec %>% as.Date(., origin="1970-01-01")
  
  rownames(dates_df) <- levels(db$Location)
  dates_df <- dates_df %>% rename(n_diff_dates=n_diff_dates_vec, top_diff_date=top_diff_date_vec, range_free = range_free_vec)
  return(dates_df)
}
dates_df <- date_range()

df_dates01 <- dates_df[1:7,]
df_dates02 <- dates_df[8:14,]
df_dates03 <- dates_df[15:21,]
df_dates04 <- dates_df[22:28,]
df_dates05 <- dates_df[29:35,]
df_dates06 <- dates_df[36:42,]
df_dates07 <- dates_df[43:49,]


df_dates01 <- df_dates01 %>% kbl(., booktabs = T , align = "c", caption = "Continuidad de las series temporales") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates02 <- df_dates02 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates03 <- df_dates03 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates04 <- df_dates04 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates05 <- df_dates05 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates06 <- df_dates06 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))
df_dates07 <- df_dates07 %>% kbl(., booktabs = T,col.names = NULL,align = "c") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))


#dates_df %>% kbl(., booktabs = T , caption = "Continuidad de las series temporales") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"), repeat_header_continued=T)

```

```{r,echo=FALSE}

df_dates01
df_dates02
df_dates03
df_dates04
df_dates05
df_dates06
df_dates07

```


Como podemos observar en el análisis anterior, vemos que la localización *NorahHead* tiene el último hueco en su serie temporal el *2013-12-31*. Es por este motivo que vamos a filtrar a partir de este valor con el fin de asegurarnos que no existan fechas faltantes dentro de las series temporales.
Se puede observar además que el resto de localizaciones tienen como último salto en su serie temporal la fecha *2013-02-28*, y que las localizaciones de *Katherine*, *Nhil* y *Uluru* comienzan su serie temporal el *2013-03-01*. Esto es, que cuando comenzó a haber registros en estas tres localizaciones dejó de haber errores de grabado de datos en la serie temporal en el resto de localizaciones (salvo en *NorahHead*). Este suceso dentro del proceso de grabación de datos podría ser indicativo de una reestructuración de los mecanismos de captación de los datos climáticos por parte del buró de meteorología australiano. 

Finalmente, filtrando desde el *2013-12-31* hasta el *2017-06-24*, que es el último dato registrado en todas las series, se puede observar en la tabla \ref{tab:Tab-4} que ya no existen discontinuidades en ninguna serie temporal.

```{r Tab-4, echo=FALSE}

# Rango de a 2013-12-31 y menor a 2017-06-24
db <- db %>% filter(.,Date>as.Date("2013-12-31") & Date<=as.Date("2017-06-24"))

# Comprobamos datos limpios
dates_df <- date_range()
dates_df %>% slice(., 1:12) %>% kbl(., booktabs = T, caption = "Muestra de series temporales desde el 2014-01-01 hasta el 2017-06-24") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))

```

## Agrupación por zona climática
 
Con el objetivo de modelar con mayor precisión los datos, vamos a realizar una segmentación de la información asignando la zona climática\footnote{\label{climate01}Desarolladas en el National Construction Code por el Buró de Metereología del Gobierno de Australia.} a la que pertenece cada localización. Estas zonas, representadas en la figura \ref{fig:Fig-01}, están descritas de la siguiente manera.

 - *Zona 1*: Veranos húmedos y cálidos, con inviernos cálidos.
 - *Zona 2*: Veranos húmedos y templados, con inviernos suaves.
 - *Zona 3*: Veranos secos y cálidos, con inviernos cálidos.
 - *Zona 4*: Veranos secos y cálidos, con inviernos frescos.
 - *Zona 5*: Clima templado.
 - *Zona 6*: Clima suave.
 - *Zona 7*: Clima fresco.
 - *Zona 8*: Clima alpino.


```{r Fig-01, out.width="90%", echo=FALSE, fig.cap="\\centering Mapa de las zonas climáticas de Australia - \\footnotesize{Fuente: Australian Building Codes Board}",fig.align='center'}
url <- "../pics/PD_Design_Climate_2.png"
knitr::include_graphics(url)
# Mapa de las zonas climáticas de Australia  - \\newline{} \\footnotesize{Fuente: Australian Building Codes Board}
```

```{r Agrupamos por zonas climáticas, echo=FALSE}

# Creamos vectores de zonas climáticas
zona1 <- c("Exmouth", "Dampier", "PortHedland", "Broome", "Derby", "Wyndham", "TimberCreek", "Katherine","Darwin", "Oenpelli", "Borroloola", "Nhulunbuy","Burketown", "Weipa", "Cooktown", "Cairns", "Townsville")
zona2 <- c("Mackay", "Rockhampton", "Maryborough", "Brisbane", "CoffsHarbour","GoldCoast")
zona3 <- c("Goondiwindi", "Taroom","Charleville", "Longreach","Thargomindah","Birdsville","MountIsa","AliceSprings","Kulgera","Yulara","Telfer","Newman", "GascoyneJunction","Carnavon","Uluru")
zona4 <- c("Woomera","Yalgoo", "Wiluna", "KalgoorlieBoulder", "Norseman", "Merredin","Newdegate","Warburton", "Amata","Oodnadatta","CooberPedy", "Nullarbor", "Innamincka","Whyalla","BrokenHill","Tibooburra","Bourke","Ivanhoe","Mildura","Griffith","Albury","WaggaWagga","Wodonga","Dubbo","Tamworth","Shepparton","Cobar","Moree","Nhil")
zona5 <- c("Geraldton","Perth","Witchcliffe","Bunbury","MargaretRiver","Esperance","Eucla","Ceduna","PortLincoln","Adelaide","LeighCreek","Renmark","Wollongong","Sydney","SydneyAirport","Newcastle","PortMacquaire","NorahHead","PearceRAAF","Penrith","PerthAirport")
zona6 <- c("Albany","Burra","Kingscote","KingstonSE","MountGambier","Horsham","Watsonia","Melbourne","LakesEntrance","BadgerysCreek","Bendigo","Dartmoor","MelbourneAirport","Nuriootpa","Sale","SalmonGums")
zona7 <- c("Ballarat","Canberra","Bathurst","Devonport","Strahan","Launceston","Swansea","Hobart","Southport","Tuggeranong")
zona8 <- c("MountGinini")

zonas <- c(zona1,zona2,zona3,zona4,zona5,zona6,zona7,zona8)
zona_climatica <- c()

# Asignamos cada ciudad a una zona climática
for(city in levels(db$Location)){
  if(city %in% zona1){
    zona_climatica <- c(zona_climatica,1)
  }
  else if(city %in% zona2){
    zona_climatica <- c(zona_climatica,2)
  }
  else if(city %in% zona3){
    zona_climatica <- c(zona_climatica,3)
  }
  else if(city %in% zona4){
    zona_climatica <- c(zona_climatica,4)
  }
  else if(city %in% zona5){
    zona_climatica <- c(zona_climatica,5)
  }
  else if(city %in% zona6){
    zona_climatica <- c(zona_climatica,6)
  }
  else if(city %in% zona7){
    zona_climatica <- c(zona_climatica,7)
  } 
  else if(city %in% zona8){
    zona_climatica <- c(zona_climatica,8)
  } 
  else { # Los lugares sin zona climática le asignamos el 0, para luego eliminar estas observaciones
    zona_climatica <- c(zona_climatica,0)
  }
}

# Creamos dataframe de zonas climáticas
zonas_climaticas <- data.frame(levels(db$Location),zona_climatica) %>% rename(Location=levels.db.Location.)
#zonas_climaticas %>% View()

```

Una estrategia alternativa que planteamos como propuesta de mejora en este punto consistiría en realizar un clustering no supervisado, de manera que se segmenten las localizaciones en 8 categorías no equitativas. A continuación, compararíamos esta categorización no supervisada contra la categorización por zona climática para comprobar la similitud de ambas asignaciones.

En cualquier caso, en el planteamiento que proponemos hemos eliminado aquellas localizaciones donde no ha sido posible determinar la zona climática a la que pertenecen. En concreto, se han eliminado *NorfolkIsland*, *Portland*, *Richmond*, *Walpole* y *Williamtown*. A continuación se presentan en la tabla \ref{tab:Tab-5} la cantidad total de observaciones junto con la cantidad de ciudades por cada zona climática.

```{r Tab-5, echo=FALSE}

# Añadimos las zonas climáticas

db <- left_join(zonas_climaticas,db, by="Location",strings)
db$Location <- db$Location %>% as.factor()

# Eliminamos la zona climática 0
db <- db %>% filter(., zona_climatica != 0)
db <- droplevels(db)
#db$zona_climatica <- db$zona_climatica %>% as.factor()

# Contamos valores totales por zona climática:
#db %>% count(zona_climatica,name = "n_obs") %>% View()

# Contamos cantidad de ciudades por zona climática
#db %>% count(zona_climatica,Location) %>%count(zona_climatica,name="n_locations") %>%  View()

# Comprobamos datos continuos
# db %>% count(zona_climatica,Location) %>% View() # esto confirma que tenemos 1272 datos para cada ciudad

# Todo a la vez:
climate_zones_db <- db %>% count(zona_climatica,name = "n_obs") %>% left_join(.,db %>% count(zona_climatica,Location) %>%count(zona_climatica,name="n_locations"), by="zona_climatica",strings) %>% select(.,-c(zona_climatica))

rownames(climate_zones_db) <- c("Zona 1", "Zona 2", "Zona 3", "Zona 4", "Zona 5", "Zona 6","Zona 7","Zona 8")

climate_zones_db %>% kbl(., booktabs = T,caption = "Cantidad de observaciones y localizaciones por zona climática") %>% kable_styling(latex_options = c("striped","hold_position"))

```


Llegados a este punto, estamos en disposición de crear un conjunto de datos para cada zona climática, a los cuales someteremos a una limpieza y procesado de datos. Es importante aplicar este procedimiento por separado para cada zona climática ya que, entre otras técnicas, imputaremos datos faltantes. Por tanto, es necesario que la información con la que sustituimos estos valores sea coherente con la subdivisión por zonas climáticas del conjunto de datos original. 
Finalmente, tenemos el conjunto de datos segmentado en 8 zonas disjuntas, que abordaremos y modelaremos en paralelo.

```{r echo=FALSE}

db_zone1 <- db %>% filter(., zona_climatica == 1) %>% select(., -zona_climatica)
db_zone1 <- droplevels(db_zone1)
db_zone2 <- db %>% filter(., zona_climatica == 2) %>% select(., -zona_climatica)
db_zone2 <- droplevels(db_zone2)
db_zone3 <- db %>% filter(., zona_climatica == 3) %>% select(., -zona_climatica)
db_zone3 <- droplevels(db_zone3)
db_zone4 <- db %>% filter(., zona_climatica == 4) %>% select(., -zona_climatica)
db_zone4 <- droplevels(db_zone4)
db_zone5 <- db %>% filter(., zona_climatica == 5) %>% select(., -zona_climatica)
db_zone5 <- droplevels(db_zone5)
db_zone6 <- db %>% filter(., zona_climatica == 6) %>% select(., -zona_climatica)
db_zone6 <- droplevels(db_zone6)
db_zone7 <- db %>% filter(., zona_climatica == 7) %>% select(., -zona_climatica)
db_zone7 <- droplevels(db_zone7)
db_zone8 <- db %>% filter(., zona_climatica == 8) %>% select(., -zona_climatica)
db_zone8 <- droplevels(db_zone8)
# Creamos diccionario con los df para poder iterar
zonas <- list("zona1"=db_zone1,
           "zona2"=db_zone2,
           "zona3"=db_zone3,
           "zona4"=db_zone4,
           "zona5"=db_zone5,
           "zona6"=db_zone6,
           "zona7"=db_zone7,
           "zona8"=db_zone8)
#print(nrow(db) == (nrow(db_zone1) + nrow(db_zone2) + nrow(db_zone3) + nrow(db_zone4) + nrow(db_zone5) + nrow(db_zone6) + nrow(db_zone7) + nrow(db_zone8)))


```


## Calidad y limpieza de los datos

A continuación, nos disponemos a tratar los aspectos relativos a la calidad del dato. Esto es, tratamiento de valores faltates o *missings*, valores atípicos u *outliers*, normalización de los datos y balanceo de los datos.

### Missings

En la tabla \ref{tab:Tab-6} que se muestra abajo se refleja el porcentaje en tanto por ciento de valores faltantes en cada variable por zona climática.

```{r Tab-6, echo=FALSE, warning=FALSE}

# Crear función de comprobar missings
# counting missing values
get_missings <- function(){
  df_missings <- NULL;
  for(i in 1:length(zonas)){
    row <- zonas[[i]] %>% select(everything()) %>% summarise_all(funs(sum(is.na(.))))*100 / nrow(zonas[[i]])
    df_missings <- df_missings %>% rbind(.,row)
  }
  rownames(df_missings) <- c("zona1",
                              "zona2",
                              "zona3",
                              "zona4",
                              "zona5",
                              "zona6",
                              "zona7",
                              "zona8")
  return(df_missings)
  
}
df_missings <- get_missings()
# df_missings %>% View()
# 
df_missings01 <- df_missings[,1:8]
df_missings02 <- df_missings[,9:15]
df_missings03 <- df_missings[,16:23]

df_missings01 <- df_missings01 %>% kbl(., booktabs = T, caption = "Porcentaje de valores faltantes por cada zona y variable.") %>% kable_styling(latex_options = c("striped","hold_position","scale_down"))

df_missings02 <- df_missings02 %>% kbl(., booktabs = T) %>% kable_styling(latex_options = c("striped","hold_position","scale_down"))

df_missings03 <- df_missings03 %>% kbl(., booktabs = T) %>% kable_styling(latex_options = c("striped","scale_down","hold_position"))

```

```{r ,echo=FALSE}
df_missings01
df_missings02
df_missings03
```

Podemos observar que existen múltiples variables que tienen un *100%* de valores faltantes para la zona climática 8. Además, en estas mismas variables existe una gran cantidad de valores faltantes en el resto de zonas climáticas, por lo que prescindiremos de ellas por su baja calidad del dato. Las variables de las que prescindiremos aplicando este criterio son *Evaporation*, *Sunshine*, *Pressure9am*, *Pressure3pm*, *Cloud9am* y *Cloud3pm*.

```{r echo=FALSE, warning=FALSE}
for(i in 1:length(zonas)){
  zonas[[i]] <- zonas[[i]] %>% select(., -any_of(c("Evaporation", "Sunshine", "Pressure9am", "Pressure3pm", "Cloud9am", "Cloud3pm")))
}
```

Una vez eliminadas dichas variables, resta por tratar el resto de columnas que presentan valores faltantes. Fijándonos de nuevo en la tabla \ref{tab:Tab-6} vemos que, a lo más, hay un *15%* de valores faltantes para la variable *Humidity3pm* en la zona climática 1, mientras que el resto de zonas climáticas tiene menos valores faltantes en todas sus variables. Con el objetivo de presentar a los modelos datos limpios con los que puedan trabajar, vamos a imputar de diferentes maneras los datos faltantes según el tipo de dato de cada columna:

 - En las columnas numéricas, sustuiremos en cada variable los valores faltantes por el valor promedio de dicha variable en cada zona.
 - En las columnas categóricas, reemplazaremos los valores faltantes por el valor modal de cada variable en cada zona. Destacar que si el valor modal es *NA*, lo sustituiremos por el siguiente valor categórico más frecuente dentro de la zona climática.
 
La decisión del uso de estos estadísticos para imputar los valores faltantes de cada variable queda respaldada por el hecho de que el uso de estos estadísticos minimiza el impacto de la imputación sobre los propios estadísticos. Esto es, sustituir valores faltantes por la media no modifica la media de la distribución subyacente.


```{r función para calcular la moda, echo=FALSE}
calc_mode <- function(x){
  
  # List the distinct / unique values
  distinct_values <- unique(x)
  
  # Count the occurrence of each distinct value
  distinct_tabulate <- tabulate(match(x, distinct_values))
  top <- which.max(distinct_tabulate) 
  # Return the value with the highest occurrence
  mode <- distinct_values[top]
  if(is.na(mode)){
    top <- distinct_tabulate[distinct_tabulate!=distinct_tabulate[top]] %>% which.max()
    mode <- distinct_values[top]
  }
  return(mode)
}
```


```{r Replace missings, echo=FALSE}
# mutate missing values

#columnas_enteras <- zonas[[1]][, unlist(lapply(zonas[[1]], is.integer), use.names = FALSE) ] %>% colnames()
columnas_numericas <- zonas[[1]][, unlist(lapply(zonas[[1]], is.numeric), use.names = FALSE) ] %>% colnames() #%>% setdiff(.,columnas_enteras)
columnas_categoricas <- zonas[[1]][, unlist(lapply(zonas[[1]], is.factor), use.names = FALSE) ] %>% colnames()

# reemplazamos variables continuas por la media
for(i in 1:length(zonas)){
  zonas[[i]] <- zonas[[i]] %>% mutate_at(columnas_numericas, ~replace_na(.,mean(., na.rm = TRUE))) 
}

# reemplazamos variables enteras por la media truncada
# for(i in 1:length(zonas)){
#   zonas[[i]] <- zonas[[i]] %>% mutate_at(columnas_enteras, ~replace_na(.,floor(mean(., na.rm = TRUE)))) 
# }

# reemplazamos variables categóricas por la moda
for(i in 1:length(zonas)){
  zonas[[i]] <- zonas[[i]] %>% mutate_at(columnas_categoricas, ~replace_na(.,calc_mode(.))) 
}

df_missings <- get_missings()
# df_missings %>% View()

```

Vemos finalmente en la tabla \ref{tab:Tab-8} que tras el proceso de imputación detallado anteriormente ya no contamos con ningún valor faltante en ninguna variable.

```{r Tab-8,echo=FALSE}
t <- sort(sample(1:ncol(df_missings),8))
df_missings01 <- df_missings %>% select(.,all_of(t))


df_missings01 <- df_missings01 %>% kbl(., booktabs = T, caption = "Muestra de variables con valores faltantes imputados.") %>% kable_styling(latex_options = c("striped","hold_position","scale_down"))

df_missings01

```


### Outliers

Mostramos a continuación una serie de diagramas de cajas y violín para cada variable separado por valor de la variable objetivo, para cada zona climática.

```{r Get outliers, echo=FALSE}

get_outliers <- function(){
  saved_plots <- list.files("../pics/plots/outliers/") 
  plots_list <- list()
  if(length(saved_plots)<8){
    for(i in 1:length(zonas)){
      ps <- list()
      db_temp <- zonas[[i]][,c(columnas_numericas)]
      for(colu in db_temp %>% colnames() %>% setdiff(.,"RainTomorrow")){
        p <- ggplot(zonas[[i]], aes_string(x="RainTomorrow", y=colu, color="RainTomorrow")) + geom_violin() + geom_boxplot(width=0.25) + stat_boxplot(geom = "errorbar", width = 0.2) + theme(
          axis.text.x = element_blank(),
          axis.text.y = element_text(size=6),
          axis.title.x = element_text(size = 8),
          axis.title.y = element_text(size = 8),
          legend.key.size = unit(0.1, 'cm'),
          legend.text = element_text(size=8),
          legend.title = element_blank())
        ps[[colu]] <- p
      }
      new_name <- paste0("zona",as.character(i))
      plots_list[[new_name]] <- ggarrange(plotlist =  ps, nrow = 4,ncol = 3,common.legend = TRUE)
      ggexport(plots_list[new_name],filename = paste0("../pics/plots/outliers/out0",as.character(i),".png"),width = 630, height = 576)
      dev.off()
    }
    return(plots_list)
    } else{for(i in 1:length(zonas)){
      new_name <- paste0("zona",as.character(i))
      p <- ggdraw() +draw_image(paste0("../pics/plots/outliers/out0",as.character(i),".png"))
      plots_list[[new_name]] <- p
      
    }
      return(plots_list)
    }
}

plot_list <- get_outliers()


```

```{r Fig-02,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 1, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[1]]

p


```

```{r Fig-03,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 2, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[2]]

p


```

```{r Fig-04,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 3, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[3]]

p


```

```{r Fig-05,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 4, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[4]]

p


```

```{r Fig-06,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 5, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[5]]

p


```

```{r Fig-07,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 6, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[6]]

p


```

```{r Fig-08,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 7, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[7]]

p


```

```{r Fig-09,echo=FALSE,fig.cap="Boxplots y violin plots de las variables de la Zona 8, según el valor de `RainTomorrow`", message=FALSE,results='hide', out.height="40%",fig.align = 'center'}

p <- plot_list[names(plot_list)[8]]

p


```


Debido a la naturaleza caótica del tiempo, no vamos a tratar los outliers como valores atípicos porque consideramos que son de valor para el entrenamiento de los modelos y no introducen demasiado ruido. Nos limitaremos entonces a realizar una normalización de los datos numéricos junto con una selección de variables aplicando por un algoritmo de *ranking* de variables tipo *step*.

No obstante, si que es posible en este punto estimar qué variables van a ser más relevantes para los modelos en cada zona. En aquellas variables en donde exista una gran diferencia visual entre el caso `RainTomorrow=YES` y el caso `RainTomorrow=NO` tendremos que las variables aleatorias subyacentes en estos casos son diferentes, y por tanto aportarán más información al modelo. De este modo, estas variables son `WindGustSpeed`, `WindGustSpeed9am`, `MinTemp`, `WindGustSpeed`, `Humidity9am` y `Humidity3pm`, dependiendo de si nos encontramos en una u otra zona climática.

Finalmente, en la tabla \ref{tab:Tab-9} comprobamos si la variable `RainTomorrow` tiene categorías balanceadas en caza zona. Se puede observar que existe cierta desproporción ya que hay valores inferiores al $30%$ de casos de lluvia en todas las zonas, especialmente la zona 3 con sólamente un $7%$ de valores positivos. Si tras un primer modelado no consiguiéramos unos resultados satisfactorios, una técnica que podría aplicarse, conocida como *downsampling*, consiste en seleccionar un subconjunto de entrenamiento donde los casos de la variable objetivo estén más proporcionados.

```{r Tab-9, echo=FALSE}

perct_rain_tomorrow <- c()

for(i in 1:length(zonas)){
  perct_rain_tomorrow <- c(perct_rain_tomorrow,(table(zonas[[i]]$RainTomorrow)[['Yes']])*100/nrow(zonas[[i]]))
}
prain_df <- data.frame(perct_rain_tomorrow,row.names = c("Zona1", "Zona2", "Zona3", "Zona4", "Zona5", "Zona6", "Zona7", "Zona8"))

prain_df %>% kbl(., booktabs = T, caption = "Índice de lluvia por zona climática") %>%kable_styling(latex_options = c("striped","hold_position"))

```


### Transformación de las variables categóricas

Las variables categóricas que disponemos son *Location*, *WindGustDir*, *WindDir9am*, *WindDir3pm*, *RainToday* y *RainTomorrow*. Para la variable *Location* vamos a aplicar técnicas de one hot encoding con las que transformaremos estas variables en numéricas. Las variables *RainToday* y *RainTomorrow* por ser binarias no necesitan ninguna transformación más que cambiar su tipo de `TRUE` y `FALSE` a unos y ceros (tipo numérico). Por otro lado, para las variables categóricas relativas a la dirección del viento, vamos a aplicar una transformación de forma que combinemos esta información con las variables enteras relativas a la intensidad del viento, obteniendo dos variables numéricas que expresan el valor del coseno y del seno del vector viento.


```{r Transformación de variables categóricas, echo=FALSE}

# Iterar por zonas
for(i in 1:(length(zonas)-1)){
  dmy <- dummyVars( ~ +Location, data = zonas[[i]])
  trsf <- data.frame(predict(dmy, newdata = zonas[[i]]))
  zonas[[i]] <- zonas[[i]] %>% select(., -any_of(c("Location"))) %>% cbind(.,trsf)
  zonas[[i]][,c("RainToday","RainTomorrow")] <- lapply(zonas[[i]][,c("RainToday","RainTomorrow")],function(x) as.numeric(x)-1) %>% as.data.frame() 
}

zonas[[8]] <- zonas[[8]] %>% select(., -any_of(c("Location"))) 
zonas[[8]][,c("RainToday","RainTomorrow")] <- lapply(zonas[[8]][,c("RainToday","RainTomorrow")],function(x) as.numeric(x)-1) %>% as.data.frame() 
# zonas[[1]] %>% head() %>% View()
```

Del proceso de *one hot encoding* podemos estacar que en la zona 8 se ha eliminado la variable `Location` ya que esta sólamente tenía un único valor, por lo que no aporta información al modelado para esta zona. Además, se han creado variables numéricas del tipo `Location.Katherine` que indican si la observación pertenece o no a dicha localización. De esta manera, tras el proceso de *one hot encoding*, explotamos cada variable categórica con *n* niveles en *n* variables binarias, conocidas como *dummy variables*.

Tras el tratamiento de esas variables categóricas, vamos a asignar un valor en radianes a cada dirección del viento según se muestran en la figura \ref{fig:Fig-10}^[Fuente - @QRSAUAQ], para después calcular el coseno y el seno de dicha dirección y multiplicar ambos por la variable respectiva de intensidad del viento. Con esta transformación, condensamos todas las variables relativas a la dirección e intensidad del viento en la coordenada $x$ e $y$ del vector viento.


```{r Fig-10,echo=FALSE,fig.cap="16 direcciones del viento", message=FALSE,results='hide',out.height="40%",fig.align = 'center'}

p <- ggdraw() +draw_image(paste0("../pics/Classification-of-wind-directions.png"))
p

```


```{r Tab-10, echo=FALSE}


radianes <- list("E"=0,"ENE"=pi/8, "NE"=pi/4, "NNE"=3*pi/8, 
                 "N" = pi/2,"NNW"=5*pi/8,"NW"=3*pi/4,"WNW"=7*pi/8,
                 "W"=pi,"WSW"=9*pi/8,"SW"=5*pi/4,"SSW"=11*pi/8,
                 "S"=3*pi/2,"SSE"=13*pi/8,"SE"=7*pi/4,"ESE"=15*pi/8)

for(i in 1:length(zonas)){ # transformamos en ángulos
  zonas[[i]] <- zonas[[i]] %>% transform(., WindGustDir=radianes[as.character(zonas[[i]]$WindGustDir)])
  zonas[[i]]<-zonas[[i]] %>% mutate(., WindGustDir_x=lapply(zonas[[i]]$WindGustDir,cos)) #componente x
  zonas[[i]]<-zonas[[i]] %>% mutate(., WindGustDir_y=lapply(zonas[[i]]$WindGustDir,sin)) #componente y
  
  zonas[[i]] <- zonas[[i]] %>% transform(., WindDir9am=radianes[as.character(zonas[[i]]$WindDir9am)])
  zonas[[i]] <- zonas[[i]] %>% mutate(., WindDir9am_x=lapply(zonas[[i]]$WindDir9am,cos)) #componente x
  zonas[[i]] <- zonas[[i]] %>% mutate(., WindDir9am_y=lapply(zonas[[i]]$WindDir9am,sin)) #componente y
  
  zonas[[i]] <- zonas[[i]] %>% transform(., WindDir3pm=radianes[as.character(zonas[[i]]$WindDir3pm)])
  zonas[[i]] <- zonas[[i]] %>% mutate(., WindDir3pm_x=lapply(zonas[[i]]$WindDir3pm,cos)) #componente x
  zonas[[i]] <- zonas[[i]] %>% mutate(., WindDir3pm_y=lapply(zonas[[i]]$WindDir3pm,sin)) #componente y
  zonas[[i]] <- zonas[[i]] %>% select(., -any_of(c("WindGustDir","WindDir9am","WindDir3pm")))
  
  new_vars <- c("WindGustDir_x","WindGustDir_y","WindDir9am_x","WindDir9am_y","WindDir3pm_x","WindDir3pm_y")
  
  zonas[[i]][,new_vars] <- lapply(zonas[[i]][,new_vars],as.numeric) %>% as.data.frame()
  
  # Las multiplicamos por la intensidad respectiva del viento:
  # 
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindGustDir_x=WindGustDir_x * WindGustSpeed)
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindDir9am_x=WindDir9am_x * WindSpeed9am)
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindDir3pm_x=WindDir3pm_x * WindSpeed3pm)
  
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindGustDir_y=WindGustDir_y * WindGustSpeed)
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindDir9am_y=WindDir9am_y * WindSpeed9am)
  zonas[[i]] <- zonas[[i]] %>% rowwise() %>% mutate(., WindDir3pm_y=WindDir3pm_y * WindSpeed3pm)
 
  zonas[[i]] <- zonas[[i]] %>% select(., -any_of(c("WindGustSpeed","WindSpeed9am","WindSpeed3pm"))) 
}



zonas[[i]] %>% head() %>% kbl(., booktabs = T, caption = "Conversión de variables de viento") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))



```

Con este proceso, hemos transformado las variables categóricas `WindGustDir`, `WindDir9am` y `WindDir3pm` en dos componentes numéricas, combinándolas respectivamente con `WindGustSpeed`, `WindSpeed9am` y `WindSpeed3pm`.

### Normalización de datos.

Como útima etapa del tratamiento de datos, nos disponemos a aplicar una normalización estándar sobre las variables numéricas que disponemos que no sean tipo *one hot*. El objetivo de este proceso es que todas tengan el mismo peso en la etapa de modelado, además de ser clave ya que vamos a trabajar con modelos basados en distancias. Vemos en la tabla \ref{tab:Tab-11} como el valor de todas las variables numéricas ha pasado a estar entre $-1$ y $1$, salvo las de tipo *one hot* que mantendremos en $[0,1]$.

```{r Tab-11, echo=FALSE}



for(i in 1:length(zonas)){
  columnas_numericas <- zonas[[i]][, unlist(lapply(zonas[[i]], is.numeric), use.names = FALSE) ] %>% colnames()
  locations <- grep("^Location.[a-zA-Z0-9]*", columnas_numericas, value = TRUE) 
  columnas_numericas <- columnas_numericas[! columnas_numericas %in% c(locations,"RainToday","RainTomorrow")]
  zonas[[i]][,columnas_numericas] <- lapply(zonas[[i]][,columnas_numericas],function(x) (x-mean(x))/(sd(x))) %>% as.data.frame()
}


columnas_numericas <- zonas[[3]][, unlist(lapply(zonas[[3]], is.numeric), use.names = FALSE) ] %>% colnames()
zonas[[3]] %>% head() %>% kbl(., booktabs = T, caption = "Variables normalizadas a 0-1 -- Zona 3") %>% kable_styling(latex_options = c("striped","HOLD_position","scale_down"))

```


## Eliminación de variables y representación de los datos

### Feature selection

RESUMEN DE TODO: 
- Las columnas categóricas son:"Location"     "WindGustDir"  "WindDir9am"   "WindDir3pm"   "RainToday"    "RainTomorrow". Vamos a sustituir las Wind_cosas por dos variables cada una, que indican el valor del seno (componente norte-sur) y el coseno(componente este-oeste) de la dirección del viento. Además, como tenemos información de la intesidad del viento por hora, multiplicaremos estos valores para agregar la información. Con este criterio, transformamos variablas variables numéricas y categóricas, las cuales con el resto de variables numéricas someteremos a un algoritmo step para seleccionar las más relevantes para el modelado. Adicionalmente, nos restan las variables categóricas "Location" y "RainToday", las cuales someteremos a un onehot encoding para el modelado.



**Con las numéricas normalizamos y hacemos el step* y con las categóricas hacemos PCA   

Factorial Analysis of Mixed Data (FAMD)

As presented in^[An Introduction to Variable and Feature Selection - @AITFS], hemos seguido los pasos que proponen a la hora de trabajar, es decir:

 - Cosas de la lista
 
```{r step for selecting most relevant numeric variables, eval=FALSE}

summary(lm1 <- lm(Fertility ~ ., data = swiss))
slm1 <- step(lm1)
summary(slm1)
slm1$anova

```



## Creación de nuevas variables ventana para trend y seasonality

Crear ventanas para RainToday de estadísticos rolling patrá

## Modelado

### Train-test split